# ----------------------------------------------
# Step 1: Import necessary libraries
# ----------------------------------------------
import pandas as pd                  # For data manipulation and analysis
import matplotlib.pyplot as plt      # For creating static plots
import seaborn as sns                # For beautiful statistical plots
from sklearn.cluster import KMeans   # For performing KMeans clustering
from sklearn.preprocessing import LabelEncoder  # To convert categorical genre to numerical

# ----------------------------------------------
# Step 2: Load the dataset
# ----------------------------------------------
df = pd.read_csv('mallCustomers.csv')  # Replace with correct path if needed

# ----------------------------------------------
# Step 3: Clean column names
# ----------------------------------------------
# Remove leading/trailing spaces and replace spaces with underscores for easier access
df.columns = [col.strip().replace(' ', '_') for col in df.columns]

# ----------------------------------------------
# Step 4: Encode the 'Genre' column
# ----------------------------------------------
# Convert 'Genre' (Male/Female) into numeric values (Male = 1, Female = 0)
# This step is helpful for numerical analysis, clustering, and plotting
le = LabelEncoder()
df['Genre'] = le.fit_transform(df['Genre'])

# ----------------------------------------------
# Step 5: Initial data overview
# ----------------------------------------------
# Print the first 5 rows of the dataset to understand its structure
print("First 5 rows of data:")
print(df.head())

# Show the datatype of each column to understand how the data is represented
print("\nData Types:")
print(df.dtypes)

# Check for missing values in the dataset
print("\nMissing Values:")
print(df.isnull().sum())

# Get a basic statistical summary of numeric columns (like mean, min, max)
print("\nStatistical Summary:")
print(df.describe())

# ----------------------------------------------
# Step 6: Correlation heatmap
# ----------------------------------------------
# Create a heatmap to visualize relationships between numeric variables
# This helps understand correlations like between age, income, and spending score
plt.figure(figsize=(8, 5))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Heatmap')
plt.show()

# ----------------------------------------------
# Step 7: Visualizing feature distributions
# ----------------------------------------------
# Plotting histograms of key features: Age, Annual Income, Spending Score, and Gender distribution
# These plots help in understanding the spread and frequency of data

plt.figure(figsize=(18, 5))

# Age distribution
plt.subplot(1, 4, 1)
sns.histplot(df['Age'], kde=True, color='skyblue')
plt.title('Age Distribution')

# Annual income distribution
plt.subplot(1, 4, 2)
sns.histplot(df['Annual_Income_(k$)'], kde=True, color='salmon')
plt.title('Annual Income Distribution')

# Spending score distribution
plt.subplot(1, 4, 3)
sns.histplot(df['Spending_Score_(1-100)'], kde=True, color='limegreen')
plt.title('Spending Score Distribution')

# Gender count plot (Male/Female count)
plt.subplot(1, 4, 4)
sns.countplot(x='Genre', data=df, palette='Set2')
plt.title('Gender Count')

plt.tight_layout()
plt.show()

# ----------------------------------------------
# Step 8: Scatter plot to visualize 2D relationship
# ----------------------------------------------
# Plot a scatter plot of Annual Income vs Spending Score
# Each point is color-coded by the 'Genre' (encoded as 0 for Female and 1 for Male)

plt.figure(figsize=(8, 6))
plt.scatter(
    df['Annual_Income_(k$)'],
    df['Spending_Score_(1-100)'],
    c=df['Genre'],  # Color points based on the encoded 'Genre'
    cmap='coolwarm',
    s=50
)
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.title('Customer Data Colored by Gender')
plt.show()

# ----------------------------------------------
# Step 9: Select features for clustering
# ----------------------------------------------
# Use only 'Annual Income' and 'Spending Score' as the features for clustering
# These features are selected because they provide meaningful insights for segmentation

data = df[['Annual_Income_(k$)', 'Spending_Score_(1-100)']]

# ----------------------------------------------
# Step 10: Elbow Method to find optimal k
# ----------------------------------------------
# The elbow method helps determine the optimal number of clusters by plotting inertia
# Inertia is the sum of squared distances from each point to its assigned cluster center

inertia = []
for k in range(1, 11):  # Test cluster counts from 1 to 10
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(data)
    inertia.append(kmeans.inertia_)  # Inertia is calculated for each value of k

# Plot the elbow curve to determine the optimal k (the 'elbow' point)
plt.figure(figsize=(6, 4))
plt.plot(range(1, 11), inertia, marker='o')
plt.xlabel('Number of Clusters')
plt.ylabel('Inertia')
plt.title('Elbow Method for Optimal K')
plt.grid(True)
plt.show()

# ----------------------------------------------
# Step 11: Apply KMeans clustering (using k=5 based on elbow curve)
# ----------------------------------------------
# After observing the elbow plot, k=5 seems to be the optimal number of clusters
# Perform KMeans clustering with k=5 and assign each customer to a cluster

kmeans = KMeans(n_clusters=5, random_state=42)
df['Cluster'] = kmeans.fit_predict(data)

# ----------------------------------------------
# Step 12: Visualize clusters
# ----------------------------------------------
# Visualize the customer clusters on a scatter plot
# Each cluster will have a different color, and the centroids will be marked with 'X'

plt.figure(figsize=(8, 6))
colors = ['red', 'green', 'blue', 'purple', 'orange']  # Assigning colors to clusters
for cluster in range(5):
    clustered_data = df[df['Cluster'] == cluster]
    plt.scatter(
        clustered_data['Annual_Income_(k$)'],
        clustered_data['Spending_Score_(1-100)'],
        s=50,
        label=f'Cluster {cluster}',
        color=colors[cluster]
    )

# Plot the centroids of the clusters
centroids = kmeans.cluster_centers_
plt.scatter(
    centroids[:, 0], centroids[:, 1],
    s=200, c='black', marker='X', label='Centroids'
)

plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.title('Customer Segments')
plt.legend()
plt.grid(True)
plt.show()

# ----------------------------------------------
# Step 13: Summarize each cluster
# ----------------------------------------------
# Group the data by clusters and calculate the mean values of income, spending score, and gender
# This helps understand the characteristics of each cluster

print("\nCluster Summary (Mean values):")
cluster_summary = df.groupby('Cluster')[['Annual_Income_(k$)', 'Spending_Score_(1-100)', 'Genre']].mean()
print(cluster_summary)